1. 编译：
	1.1 opencv3.4.5: set(CMAKE_PREFIX_PATH) → 修改camera_model的cmakelists.txt的include opencv
		set(CMAKE_PREFIX_PATH "/usr/local/include/opencv3.4.5")
		find_package(OpenCV 3.4)
		if(NOT OpenCV_FOUND)
		    find_package(OpenCV 3.0)
		    if(NOT OpenCV_FOUND)
		        message(FATAL_ERROR "OpenCV > 3.0 not found.")
		    endif()
		endif()
		MESSAGE("OPENCV VERSION:")
		MESSAGE(${OpenCV_VERSION})
	1.2 ceres: https://github.com/ceres-solver/ceres-solver
		1.2.1 mkdir build
		1.2.2 cd build
		1.2.3 cmake ..
		1.2.4 make -j8
		1.2.5 make test
		1.2.6 sudo make install
	1.3 编译vins-mono
		1.3.1 mkdir -p catkin_ws/src
		1.3.2 将vins-mono文件夹放到src下
		1.3.3 catkin_init_workspace
		1.3.4 cd ..
		1.3.5 catkin_make
	1.4 运行测试数据
		1.4.1 新开终端：source devel/setup.bash roscore
		1.4.2 新开终端：source devel/setup.bash roslaunch vins_estimator euroc.launch 
		1.4.3 新开终端：source devel/setup.bash roslaunch vins_estimator vins_rviz.launch
		1.4.4 新开终端：source devel/setup.bash rosbag play YOUR_PATH_TO_DATASET/MH_01_easy.bag 
		1.4.5 为了避免每次都source devel/setup.bash：https://blog.csdn.net/github_53583003/article/details/111187288
			1. sudo  gedit ~/.bashrc
			2. 添加：source ~/devel/setup.bash
	1.5 在clion中打开
		1.5.1 在catkin_ws下，source devel/setup.bash
		1.5.2 ./clion.sh
		1.5.3 使用src下面的camkelists.txt加载
		1.5.4 使用当前窗口，不要新建窗口，新建窗口的话，source就是去意义了，然后正常编译即可

2. camera model
	2.1 抽象类：Camera
		2.1.1 负责创建一些公有变量和公有函数，有一些函数是纯虚函数，继承类必须重写
		2.1.2 创建有大量的用于标定的函数，暂时不学习与标定相关的函数
		2.1.3 比较有意思的是函数reprojectionDist：其评价的是两个相机系下的三维点，在同一个相机下投影到图像上，它们的像素坐标的差值作为重投影误差

	2.2 继承类：PINHOLE
		2.2.1 继承抽象的父类Camera，创建针孔相机
		2.2.2 创建有大量的用于标定的函数，暂时不学习与标定相关的函数；其中函数estimateIntrinsics用于实现张正友博士的Z. Zhang, A Flexible New Technique for Camera Calibration, PAMI 2000
		2.2.3 liftProjective快速去畸变：
			1. 巧妙设计了一种快速去畸变的方法，用于快速求解畸变前的归一化相机系坐标
			2. 注意，当畸变为外扩时，如果第一次修正后的归一化坐标不在当前的1/4图像时，此算法无法收敛；但是需要注意的是，一般畸变都不大（至少不会大到出现跨越图像1/4区域的情况），其次，越靠近图像中心，畸变就越小，因此，这种异常情况是不会发生的

	2.3 继承类：Equidistant，使用的是KB8模型
		2.3.1 继承抽象的父类Camera，创建鱼眼相机，注意其参数是k2~k5与一般的k1~k4不同
		2.3.2 创建有大量的用于标定的函数，暂时不学习与标定相关的函数；其中函数estimateIntrinsics用于实现C. Hughes, P. Denny, M. Glavin, and E. Jones, Equidistant Fish-Eye Calibration and Rectification by Vanishing Point；Extraction, PAMI 2010 Find circles from rows of chessboard corners, and for each pair of circles, find vanishing points: v1 and v2. 
		2.3.3 liftProjective
			1. 将像素坐标（u, v）变换为畸变后的归一化相机系坐标(xd, yd)
			2. 使用backprojectSymmetric求解theta和phi
			3. 将(xd, yd)通过theta和phi变化到去畸变前的相机归一化坐标系下，并单位化，从而变换到球面上
		2.3.4 backprojectSymmetric
			1. 相机系下的三维点A与光心的连线与归一化相机系平面交于B1（对应r），经过畸变后与归一化相机系平面交于B2（对应theta_d）；有B1、B2和归一化平面的原点O三点共线
			2. 由于O、B1和B2共线，所以可以直接通过xd, yd计算phi
			3. 对theta的求解：将关于theta的多项式函数令为矩阵A的特征多项式（转化方法见代码），然后调用Eigen的接口求解最小的特征多项式

	2.4 继承类：Scaramuzza --- 暂时不深究
		2.4.1 继承抽象的父类Camera，创建全景相机模型Scaramuzza
		2.4.2 参考教程为：
			1. https://blog.csdn.net/j879159541/article/details/125566948
			2. https://sites.google.com/site/scarabotix/ocamcalib-toolbox

	2.5 继承类：CataCamera --- 暂时不深究
		2.5.1 继承抽象的父类Camera，创建全景相机模型Mei
		2.5.2 参考教程为：
			1. https://blog.csdn.net/j879159541/article/details/125409410
			2. C. Mei, and P. Rives, Single View Point Omnidirectional Camera Calibration from Planar Grids, ICRA 2007

3. feature tracker
	3.1 特征点存储信息：
		3.1.1 像素坐标 → 特征点提取算法
		3.1.2 去畸变后归一化坐标 → 特征点去畸变算法
		3.1.3 特征点id → 光流跟踪算法
		3.1.4 特征点速度 → 时间同步算法使用

	3.2 快门（shutter）: https://blog.csdn.net/weixin_43503508/article/details/108014615
		3.2.1 全局快门（Global Shutter）
			1. 通过整幅场景在同一时间曝光实现的。Sensor所有像素点同时收集光线，同时曝光。即在曝光开始的时候，Sensor开始收集光线；在曝光结束的时候，光线收集电路被切断。然后Sensor值读出即为一幅照片。CCD就是Global shutter工作方式。所有像元同时曝光。
			2. 曝光时间更短，但会增加读出噪声；
		3.2.2 卷帘快门（Rolling Shutter）
			1. 与Global shutter不同，它是通过Sensor逐行曝光的方式实现的。在曝光开始的时候，Sensor逐行扫描逐行进行曝光，直至所有像素点都被曝光。当然，所有的动作在极短的时间内完成。不同行像元的曝光时间不同。
			2. 对于相机厂家，Rolling shutter可以达到更高的帧速，但当曝光不当或物体移动较快时，会出现部分曝光(partial exposure)、斜坡图形(skew)、晃动(wobble) 等现象。这种Rolling shutter方式拍摄出现的现象，就定义为果冻效应。
		3.2.3 曝光时间短的应用（如<500μs）适合Global shutter，曝光时间长（如大于500μs）时，选择rolling shutter可以有更低的噪声和帧速。

	3.3 readParameters
		3.3.1 读取配置文件的信息：image_topic、imu_topic等
		3.3.2 将配置文件路径添加到CAM_NAMES中，实际上这是一个单目VIO系统，CAM_NAMES的size仅仅为1
		3.3.3 设置WINDOW_SIZE(20)、FOCAL_LENGTH(460)

	3.4 readIntrinsicParameter：创建相机，并读取相机的内参数、畸变稀疏和相机类型等

	3.5 img_callback
		3.5.1 第一帧的时候，first_image_flag为true，此时，将时间戳存储到first_image_time和last_image_time，并令first_image_flag为false，然后直接结束
		3.5.2 如果当前帧的时间戳减去上一帧的时间戳（last_image_time）大于1秒（光流法需要两帧之间的间距尽可能小）或者当前时间戳小于上一帧时间戳，那么执行reset为初始值：first_iamge_flag为true，last_image_time为0，pub_count为1，将重启告诉其他模块，并直接结束
		3.5.3 更新last_image_time，并维持发给后端的图像数量不会超过指定的频率；将ros message转化为cv::Mat
		3.5.4 createCLAHE：
			1. equalizeHist：
				1.1 对图片灰度图做频数统计，计算器频率，然后根据像素灰度值进行排列
		        1.2 根据像素灰度值计算累计概率，利用公式：new_gray = acc_p * (255 - 0)
		        1.3 这样做的目的是使得灰度值之间的间隔更小，即将一些频数较大的灰度值补充给了频数较小的灰度值，从而实现了灰度值的均衡化
		        1.4 由于整体亮度的提升，也会使得局部图像的细节变的模糊，因此最好进行分块的局部均衡化，参考createCLAHE
		    2. 对图像进行分块后执行equalizeHist
		    3. 参考教程：
		    	3.1 https://www.cnblogs.com/my-love-is-python/p/10405811.html
		    	3.2 https://en.wikipedia.org/wiki/Histogram_equalization
		3.5.5 readImage:读取图像，并做光流跟踪
			1. 获取当前时间，并且如果EQUALIZE为true，那么就对图像执行createCLAHE，并将结果赋值给img
			2. 更新forw_img，如果是第一帧的话，直接将图像赋值给cur_img和forw_img；如果上一帧有特征点的话：
				2.1 执行光流跟踪calcOpticalFlowPyrLK
				2.2 利用光流跟踪返回的状态值和图像边界删除外点
				2.3 利用reduceVector对cur_pts、forw_pts、ids、cur_un_pts和track_cnt的规模进行删减，并且不会改变原有的顺序：
					2.3.1 利用双指针实现，j指针指向数据，i指针指向状态，只有状态为true的时候，才会将v[j]=v[i]，类似于用v[i]覆盖v[j]
					2.3.2 对数据resize即可
			3. 如果publish这一帧的话，那么：
				3.1 rejectWithF：对极约束剔除外点，第一帧没有对极约束
					3.1.1 
				3.2 setMask：特征点均匀化，第一帧不做均匀化
					3.2.1 
				3.3 根据所需的特征点数量减去跟踪到的特征点数量，获得还需要提取的特征点数量，然后执行特征点提取操作goodFeaturesToTrack：
					3.3.1 
				3.4 将提取的角点添加到相应的容器中addPoints：
					3.4.1 
			4. 更新cur_img为forw_img，cur_pts为forw_pts；对特征点进行去畸变undistortedPoints:
				4.1 
			5. 更新prev_time为cur_time；令人比较迷惑的是，cur_img和cur_pts表示上一帧的图像和特征点，而cur_time表示当前时间

		3.5.6 给新的特征点赋上ID，updateID：
			1. 如果没有越界，并且是新的特征点，那么id=n_id，并且n_id递增，并返回true；否则，直接返回false

		
			 






git: 























1. 在初始化阶段比较难估计的变量有：相机与IMU的平移外参、加速度计的零偏；对于前者可以用尺子量一下，对于后者，即使在初始化阶段忽视它，也不会有太大的问题，后面会一直优化它



目前尚未明白的点：
	1. 零偏只是在一个区间内保持不变进行建模，但是并不是一直不变；因此，程序里面应该有多个零偏需要估计，是否每次开始的时候的零偏都是从0开始估计
	2. 在递推计算tmp_Q的过程中，由于使用了近似计算，使得tmp_Q并不是单位四元数，这是否会对后面的计算产生影响
	3. 此处使用的是归一化的相机坐标系的坐标，如果按照针孔模型的话，要达到10的间隔，说明像素间隔有几千了，是否在前面做了什么处理
	4. 初始化的all image frame是什么，其与初始化的时候的关键帧集合有什么不同
	5. 为什么视觉惯性对齐后又要进行三角化，这是在做什么
	6. 视觉重投影中的T_wbi是什么，这是直接计算的，还是通过了相机；如果是直接计算的，那么两帧之间的距离就不能很远
	7. 为什么旋转有时候是矩阵有时候是四元数，而且求导的方式还不一样，明明参数设置的是四元数，这样做有什么理论依据吗？
	8. 在ORB-SLAM的局部建图BA中，对于局部建图中的地图点，如果有观测不在局部建图中，就将其固定；在VINS-MONO的滑动窗口优化中，为什么要固定窗口中的第一帧，是因为滑动窗口优化中没有使用窗口之外的信息，所以需要固定一帧？
	9. 为什么重力的存在使得自由度为4，不是在静止的时候才有pitch和roll可观吗？很多地方都只优化了yaw和平移，没有优化roll和pitch
	10. 为什么要保持第一帧的yaw不变，为什么平移和速度需要补偿yaw？
	11. 边缘化倒数第二帧是什么意思？


需要后面注意看的点：
	1. 视觉重投影的误差的权重是如何给的：1.5倍


知识点：
	1. VINS里面边缘化后无法使用schur complement技术，是因为帧与帧之间有IMU构建的预积分约束，导致了稠密矩阵的产生；如果仅仅是重投影误差，即使边缘化某些状态，也不会影响到地图点对应的部分的稀疏性



1. 查看VINS-MONO中动态优化Tbc的方法：
	1.1 如果传入参数为2
		1.1.1 没有任何外参信息，
		1.1.2 根据q_cb * q_bkbk+1 = q_ckck+1 * q_cb = q_ckbk+1进行初始化计算旋转外参（平移外参初始化不计算，赋值为0向量），并且在帧数小于WINDOW_SIZE时，重复计算（使用kernel function）
		1.1.3 在后面的滑窗优化中，根据重投影误差进一步优化旋转外参和平移外参
	1.2 如果传入参数为1
		1.2.1 说明有初始值，不进行旋转外参初始化
		1.2.2 在后面的滑窗优化中，根据重投影误差进一步优化旋转外参和平移外参
	1.3 如果传入参数为0
		1.3.1 表示外参非常准确，既不需要进行旋转外参初始化也不需要在后面的滑窗优化中去优化它不需要优化




发同步时间戳的代码


核验数据、


前端：
	1. 光流跟踪
		提取特征点：
			1. 使用createCLAHE对图像进行处理，防止图像太亮或者太暗，不利于提取特征点
			2. 使用图像金字塔进行光流追踪，上层结果为下层初值，提升光流追踪的稳定性，这里使用的4层，使用calcOpticalFlowPyrLK进行光流追踪
			3. 使用对极约束去除外点，根据极线方程，计算像素点到极线的距离进行筛选
			4. 特征点均匀化：先对特征点的质量进行排序，排序规则是根据追踪的次数，追踪到的次数越多，质量越好，然后画圈，圈内排斥其他特征点，进行特征点的均匀化
			5. 判断是否需要重新提取特征点，如果需要就提取到指定的特征点
			6. 对提取到的特征点统一进行去畸变，并计算特征点速度（只有在前一帧中有对应的特征点的才能计算，否则置0），用来后续时间戳标定
			7. 对新的提取的特征点设置ID，也就是下标

		光流与特征点的对比：
			1. 光流根据前一张图片的特征点在本张图片中搜索其对应的匹配点，由于不是所有的特征点都能匹配到，因此还需要重新提取一些特征点，因此对于每张图片，其过程为：LK光流追踪，重新提取不足的部分特征点
			2. 对于特征点而言，每张图片都需要提取相同数量的特征点，还需要就是那描述子，然后还需要计算匹配（匹配比较耗时）
			总结：
				1. 特征点法会比光流耗时
				2. 光流法在特征点的追踪上会更加鲁棒
				3. 光流应用于两帧运动很小的时候，而在重定位和回环检测的运动很大，此时更适合用特征点法
				4. 如果存在遮挡的时候，特征点法会更好；例如，1→2→3，帧1、3看到了某个地图点，2没有看到，如果使用光流法，就不会认为帧1、3看到的是用一个地图点，因为2没有看到，会认为是一个新的地图点；而此时在特征点法中会认为是同一个地图点


		旋转的几种数学表示方法：
			旋转矩阵：运算方便;使用9个量描述3自由度旋转，引入额外约束，求导困难
			旋转向量：紧凑的表示旋转;具有周期性
			欧拉角：直观，用户友好;需要指定旋转顺序，存在万象节死锁问题，无法进行球面平滑插值
			四元数：紧凑的不带奇异的表示方法;对用户来讲不太直观，要求单位四元数，表示旋转也会过参数化

		ESKF：IMU预积分的结果为predict，重投影误差是update
		在优化里面，IMU的结果产生约束，影响着位姿的优化方向
		
		为什么需要卡尔曼滤波：帮助IMU预积分计算协方差的时候避免四元数过参数化（四元数对应的协方差为4*4）
			1. 使用的轴角是一个三自由度，而四元数是一个过参数的表示（4自由度，需要一个单位四元数的约束）
			2. 误差一般都在0附近，不会有轴角表示中的周期性的问题（theta和theta+2pi等价）
			3. 误差很小，可以很方便的计算易一阶导，省略二阶导也不会导致较大的误差
			4. 误差变化很小，可以不用很高频率的更新

	2.  




FEJ:
	1. https://www.zhihu.com/question/500852656/answer/2239709690
	2. https://zhuanlan.zhihu.com/p/545544042



